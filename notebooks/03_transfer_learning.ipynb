{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620310d7",
   "metadata": {},
   "source": [
    "# Pneumonia Classification in Chest X-rays using Transfer Learning <br> (ResNet-18)\n",
    "In recent years, increasing the depth of neural networks has proven crucial for enhancing their learning capacity and performance in complex tasks, such as image recognition. However, training increasingly deep networks poses significant technical challenges, particularly related to the propagation of information and gradients during training.\n",
    "\n",
    "Kaiming He and collaborators stated: \n",
    ">\"Driven by the significance of depth, a question arises: Is learning better networks as easy as stacking more layers?\" \n",
    "\n",
    "This question is precisely what ResNet addresses, a convolutional neural network (CNN) architecture whose name indicates the number of layers in the architecture. Introduced in 2015 by Microsoft, ResNet offered a solution to the vanishing gradient problem that occurred when adding extra layers, through the use of **skip connections**. The ResNet family includes models of various depths, such as ResNet-18, ResNet-34, ResNet-50, ResNet-101, and ResNet-152, each adapted to different levels of complexity and learning capacity.\n",
    "\n",
    "You can find more details in the original [ResNet paper](https://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d68fe9",
   "metadata": {},
   "source": [
    "### 1. Library Imports for Transfer Learning\n",
    "\n",
    "For the implementation of the second model, the core PyTorch libraries were utilized. Specifically, the models sub-module from torchvision was imported to access the ResNet18 architecture and its pre-trained weights. Additionally, seaborn was included to enhance the visualization of the final comparison metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb229f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core deep learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models \n",
    "\n",
    "# Data handling and preprocessing\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "# Visualization and evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# System and environment configuration\n",
    "import os\n",
    "# Disable MacOS malloc stack logging to avoid memory warnings on Apple Silicon\n",
    "os.environ[\"MallocStackLogging\"] = \"0\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "from src.data.dataloaders import get_loaders\n",
    "\n",
    "# Aesthetic settings for high-quality plots\n",
    "plt.style.use(\"seaborn-v0_8-muted\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d6c6cd",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Preprocessing\n",
    "\n",
    "The system paths were configured to access local modules and the dataloaders were initialized. \n",
    "- An image size of 228x228 was selected to balance detail and computational cost.\n",
    "- A batch size of 32 was selected as a balance between convergence stability and computational efficiency.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55950125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Silicon detected. Setting num_workers to 0 for compatibility.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data loaders are initialized using a preprocessing pipeline\n",
    "specifically adapted for ResNet architectures, including\n",
    "ImageNet normalization and conservative data augmentation.\n",
    "\"\"\"\n",
    "\n",
    "train_loader, test_loader = get_loaders(\n",
    "    batch_size=32,\n",
    "    model_type=\"resnet\"\n",
    ")\n",
    "\n",
    "assert train_loader is not None and test_loader is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d1e43",
   "metadata": {},
   "source": [
    "### 3. ResNet18 Implementation and Customization\n",
    "\n",
    "The ResNet18 architecture was adapted to serve as the primary model. Since the original model was trained on the ImageNet dataset (RGB images), the input layer was modified to process single-channel grayscale X-rays. Furthermore, the weights of the convolutional base were frozen to prevent their distortion during the initial training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "322ccbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: Apple Silicon GPU (MPS)\n",
      "The ResNet18 model was created and migrated to the device.\n"
     ]
    }
   ],
   "source": [
    "# Create a ResNet18 model using transfer learning\n",
    "def create_resnet_model(num_classes=2, dropout=0.5):\n",
    "    \"\"\"\n",
    "    Create a pre-trained ResNet18 model with a custom classifier.\n",
    "    \"\"\"\n",
    "    weights = models.ResNet18_Weights.DEFAULT\n",
    "    model = models.resnet18(weights=weights)\n",
    "    \n",
    "    # Stage 1: Freeze all convolutional layers.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final classifier.\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Device Selection.\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Training on: Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Training on: NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Training on: CPU\")\n",
    "\n",
    "model = create_resnet_model(dropout=0.5).to(device)\n",
    "print(\"The ResNet18 model was created and migrated to the device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2a548",
   "metadata": {},
   "source": [
    "### 4. Training Loop Definition\n",
    "\n",
    "A function was created to manage the training process, error calculation, and weight optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85088b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=10, patience=3):\n",
    "\n",
    "    \"\"\"\n",
    "    Training loop with early stopping, where the test set is used\n",
    "    as a validation proxy due to dataset constraints.\n",
    "    \"\"\"\n",
    "    history = {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
    "\n",
    "    # Initialization for early stopping.\n",
    "    best_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "            \n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "            \n",
    "        for images, labels in train_loader:\n",
    "                # Data was moved to the selected device (MPS/CUDA/CPU).\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "             # Gradients were reset\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            # Forward pass: Predictions were generated.\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "            # Backward pass: Gradients were calculated and weights updated.\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            # Training metrics were accumulated.\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "                \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct_train / total_train\n",
    "\n",
    "        # Evaluation Phase\n",
    "        model.eval()\n",
    "        test_loss, correct_test, total_test = 0.0, 0, 0\n",
    "            \n",
    "        # Gradient calculation was disabled for evaluation to save memory.\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                    \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "            \n",
    "        val_loss = test_loss / len(test_loader)\n",
    "        val_acc = 100 * correct_test / total_test\n",
    "            \n",
    "        # Epoch metrics were stored in history.\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['test_loss'].append(val_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        history['test_acc'].append(val_acc)\n",
    "            \n",
    "        print(f\"Train Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")\n",
    "        print(f\"Test  Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save the best model based on test loss with early stopping.\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"../models_saved/resnet_best.pth\")\n",
    "            print(\"Best model saved\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement ({epochs_no_improve}/{patience})\")\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "            \n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3acf0",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Model Training Strategy: Two-Stage Transfer Learning\n",
    "To achieve the best performance on our X-ray classification task, we implement a two-phase training strategy. This approach leverages the pre-trained weights of ResNet-18 while adapting them specifically to the nuances of medical imaging.\n",
    "\n",
    "- Phase 1: Feature Extraction\n",
    "\n",
    "In this initial stage, we freeze the backbone of the network and only train the newly added classification head (Fully Connected layer). The goal is to utilize the high-level features already learned by ResNet on ImageNet and adapt the final output to our two classes (Normal vs. Pneumonia) without distorting the pre-trained weights.\n",
    "\n",
    "- Phase 2: Fine-Tuning\n",
    "\n",
    "Once the classifier has stabilized, we unfreeze the entire architecture. By using a significantly lower learning rate (10 \n",
    "−4\n",
    " ), we allow the weights of all layers to be slightly adjusted. This \"fine-tuning\" process enables the convolutional filters to specialize in the specific textures and patterns found in chest X-rays, further refining the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a13209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting phase 1: Feature Extraction\n",
      "==================================================\n",
      "\n",
      "--- Epoch 1/10 ---\n",
      "Train Loss: 0.1891 | Acc: 92.48%\n",
      "Test  Loss: 0.3301 | Acc: 88.78%\n",
      "Best model saved\n",
      "\n",
      "--- Epoch 2/10 ---\n",
      "Train Loss: 0.1467 | Acc: 94.38%\n",
      "Test  Loss: 0.4564 | Acc: 85.90%\n",
      "No improvement (1/3)\n",
      "\n",
      "--- Epoch 3/10 ---\n",
      "Train Loss: 0.1415 | Acc: 94.44%\n",
      "Test  Loss: 0.4876 | Acc: 83.33%\n",
      "No improvement (2/3)\n",
      "\n",
      "--- Epoch 4/10 ---\n",
      "Train Loss: 0.1191 | Acc: 95.65%\n",
      "Test  Loss: 0.3907 | Acc: 86.06%\n",
      "No improvement (3/3)\n",
      "Early stopping triggered\n",
      "\n",
      "Loading best model from Phase 1 to start fine-tuning...\n",
      "\n",
      "==================================================\n",
      "Starting phase 2: Fine-tuning\n",
      "==================================================\n",
      "\n",
      "--- Epoch 1/15 ---\n",
      "Train Loss: 0.1101 | Acc: 95.78%\n",
      "Test  Loss: 0.2887 | Acc: 91.51%\n",
      "Best model saved\n",
      "\n",
      "--- Epoch 2/15 ---\n",
      "Train Loss: 0.0751 | Acc: 97.22%\n",
      "Test  Loss: 0.3331 | Acc: 89.26%\n",
      "No improvement (1/4)\n",
      "\n",
      "--- Epoch 3/15 ---\n",
      "Train Loss: 0.0628 | Acc: 98.06%\n",
      "Test  Loss: 0.4706 | Acc: 85.90%\n",
      "No improvement (2/4)\n",
      "\n",
      "--- Epoch 4/15 ---\n",
      "Train Loss: 0.0604 | Acc: 97.89%\n",
      "Test  Loss: 0.3631 | Acc: 89.10%\n",
      "No improvement (3/4)\n",
      "\n",
      "--- Epoch 5/15 ---\n",
      "Train Loss: 0.0497 | Acc: 98.31%\n",
      "Test  Loss: 0.3730 | Acc: 87.66%\n",
      "No improvement (4/4)\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Loss function and model initialization.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Stage 1: Feature Extraction\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting phase 1: Feature Extraction\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Only the parameters of the fc layer (the classifier) are optimized.\n",
    "optimizer_fe = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "history_fe = train_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer_fe, \n",
    "    epochs=10, patience=3\n",
    ")\n",
    "\n",
    "# The best model from the previous phase is loaded before unfreezing.\n",
    "print(\"\\nLoading best model from Phase 1 to start fine-tuning...\")\n",
    "state_dict = torch.load(\n",
    "    \"../models_saved/resnet_best.pth\",\n",
    "    weights_only=True,\n",
    "    map_location=device\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# Stage 2: Fine tuning.\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting phase 2: Fine-tuning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# All layers are unfrozen for fine-tuning.\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Use a much lower learning rate (10× or 100× smaller)\n",
    "optimizer_ft = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "\n",
    "history_ft = train_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer_ft, \n",
    "    epochs=15, patience=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5514fcd",
   "metadata": {},
   "source": [
    "### 6. Performance Metrics and Diagnostic Validation\n",
    "Evaluating a medical diagnostic model requires going beyond simple accuracy. In a clinical environment, the cost of a False Negative (failing to detect pneumonia) is significantly higher than a False Positive. Therefore, our evaluation process focuses on a comprehensive analysis of the model's decision-making process.\n",
    "\n",
    "The evaluate_model function performs a full pass over the unseen test set, ensuring the model's generalizability. We use torch.no_grad() to disable gradient calculation, which reduces memory consumption and speeds up computation during inference. For each image, the model outputs raw scores (logits) that we transform into probabilities using the Softmax function, allowing us to quantify the confidence of each prediction.\n",
    "\n",
    "The resulting Classification Report provides a detailed breakdown of:\n",
    "\n",
    "Precision: The accuracy of positive predictions.\n",
    "\n",
    "Recall (Sensitivity): The ability of the model to find all relevant cases of pneumonia.\n",
    "\n",
    "F1-Score: The harmonic mean of precision and recall, offering a balanced view of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "065e3c96",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.1.weight\", \"fc.1.bias\", \"fc.1.running_mean\", \"fc.1.running_var\". \n\tUnexpected key(s) in state_dict: \"fc.3.weight\", \"fc.3.bias\", \"fc.3.running_mean\", \"fc.3.running_var\", \"fc.3.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 39\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Load the best model and perform evaluation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models_saved/resnet_phase2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m     map_location\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m test_labels, test_preds, test_probs \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, device)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.1.weight\", \"fc.1.bias\", \"fc.1.running_mean\", \"fc.1.running_var\". \n\tUnexpected key(s) in state_dict: \"fc.3.weight\", \"fc.3.bias\", \"fc.3.running_mean\", \"fc.3.running_var\", \"fc.3.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Complete evaluation on the test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    test_acc = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Final Evaluation\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                                target_names=[\"NORMAL\", \"PNEUMONIA\"]))\n",
    "    \n",
    "    return all_labels, all_preds, all_probs\n",
    "\n",
    "# Load the best model and perform evaluation\n",
    "state_dict = torch.load(\n",
    "    \"../models_saved/resnet_phase2.pth\",\n",
    "    weights_only=True,\n",
    "    map_location=device\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "test_labels, test_preds, test_probs = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329b72f",
   "metadata": {},
   "source": [
    "### 5. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc68c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training curves\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history_fe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 134\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Ejecution.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# 1. Plot Learning Curves (Loss and Accuracy).\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining curves\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m plot_training_curves(\u001b[43mhistory_fe\u001b[49m, history_ft)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# 2. Plot Final Evaluation (Confusion Matrix and ROC).\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation plots\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_fe' is not defined"
     ]
    }
   ],
   "source": [
    "# Directory setups.\n",
    "# Avoids errors if the folder doesn't exist.\n",
    "\n",
    "os.makedirs(\"../results/figures\", exist_ok=True)\n",
    "\n",
    "def plot_training_curves(history_p1, history_p2):\n",
    "\n",
    "    \"\"\"\n",
    "    Plot training curves by combining Phase 1 (Feature Extraction) \n",
    "    and Phase 2 (Fine-Tuning).\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    \"\"\"\n",
    "    Combine histories from both phases:\n",
    "    - history_p1 = history_fe (Feature Extraction).\n",
    "    - history_p2 = history_ft (Fine-Tuning).\n",
    "    \"\"\"\n",
    "    \n",
    "    epochs_p1 = len(history_p1[\"train_loss\"])\n",
    "    epochs_p2 = len(history_p2[\"train_loss\"])\n",
    "    \n",
    "    # The X-axis is continuous.\n",
    "    total_epochs_range = list(range(1, epochs_p1 + epochs_p2 + 1))\n",
    "    \n",
    "    # Concatenate lists of metrics.\n",
    "    train_loss = history_p1[\"train_loss\"] + history_p2[\"train_loss\"]\n",
    "    test_loss = history_p1[\"test_loss\"] + history_p2[\"test_loss\"]\n",
    "    train_acc = history_p1[\"train_acc\"] + history_p2[\"train_acc\"]\n",
    "    test_acc = history_p1[\"test_acc\"] + history_p2[\"test_acc\"]\n",
    "\n",
    "    # Figure 1: Loss.\n",
    "    axes[0].plot(total_epochs_range, train_loss, \"o-\", label=\"Train Loss\", linewidth=2, color=\"#3498db\")\n",
    "    axes[0].plot(total_epochs_range, test_loss, \"s-\", label=\"Val/Test Loss\", linewidth=2, color=\"#e74c3c\")\n",
    "\n",
    "    # Vertical line indicating the start of fine-tuning.\n",
    "    axes[0].axvline(x=epochs_p1, color=\"black\", linestyle=\"--\", alpha=0.7, label=\"Fine-Tuning Start\")\n",
    "\n",
    "    axes[0].set_xlabel(\"Epochs\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize=12)\n",
    "    axes[0].set_title(\"Loss Evolution\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Figure 2: Accuracy.\n",
    "    axes[1].plot(total_epochs_range, train_acc, \"o-\", label=\"Train Acc\", linewidth=2, color=\"#2ecc71\")\n",
    "    axes[1].plot(total_epochs_range, test_acc, \"s-\", label=\"Val/Test Acc\", linewidth=2, color=\"#9b59b6\")\n",
    "\n",
    "    # Vertical line indicating the start of Fine-Tuning.\n",
    "    axes[1].axvline(x=epochs_p1, color=\"black\", linestyle=\"--\", alpha=0.7, label=\"Fine-Tuning Start\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Epochs\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "    axes[1].set_title(\"Accuracy Evolution\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Detect and highlight the overfitting area when the gap exceeds 10%.\n",
    "    max_gap = max([t - te for t, te in zip(train_acc, test_acc)])\n",
    "    if max_gap > 10:\n",
    "        axes[1].fill_between(total_epochs_range, train_acc, test_acc, \n",
    "                            alpha=0.1, color=\"red\", \n",
    "                            label=f\"Gap Max: {max_gap:.1f}%\")\n",
    "        axes[1].legend(fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Save figure.\n",
    "    plt.savefig(\"../results/figures/resnet_training_curves.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_and_roc(labels, preds, probs):\n",
    "    \"\"\"\n",
    "    Generate confusion matrix and ROC curve based on test set predictions.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Figure 3: Confusion Matrix \n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n",
    "                yticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n",
    "                ax=axes[0], annot_kws={\"size\": 16}, cbar=False)\n",
    "\n",
    "    axes[0].set_title(\"Confusion Matrix\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].set_ylabel(\"True Label (Ground Truth)\", fontsize=12)\n",
    "    axes[0].set_xlabel(\"Model Prediction\", fontsize=12)\n",
    "\n",
    "    # Calculate clinical metrics inside the function for visualization on the plot.\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0 # Recall PNEUMONIA\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0 # Recall NORMAL\n",
    "    \n",
    "    # Figure 4: ROC Curve.\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    axes[1].plot(fpr, tpr, linewidth=3, color=\"darkorange\", label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n",
    "    axes[1].plot([0, 1], [0, 1], \"k--\", linewidth=2, label=\"Random Classifier\")\n",
    "\n",
    "    axes[1].set_xlim([-0.02, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel(\"False Positive Rate (1 - Specificity)\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"True Positive Rate (Sensitivity)\", fontsize=12)\n",
    "    axes[1].set_title(\"ROC Curve\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].legend(loc=\"lower right\", fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Text box displaying detailed metrics.\n",
    "    stats_text = (f\"Sensitivity (Recall Pne): {sensitivity:.3f}\\n\"\n",
    "                  f\"Specificity (Recall Nor): {specificity:.3f}\\n\"\n",
    "                  f\"False Positives: {fp}\\n\"\n",
    "                  f\"False Negatives: {fn}\")\n",
    "\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.3)\n",
    "    axes[1].text(0.05, 0.95, stats_text, transform=axes[1].transAxes, fontsize=11,\n",
    "                verticalalignment=\"top\", bbox=props)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../results/figures/resnet_evaluation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Display summary in the console.\n",
    "    print(\"\\n Summary of Clinical Metrics: \")\n",
    "    print(f\"  ➢ Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"  ➢ Specificity: {specificity:.4f}\")\n",
    "    print(f\"  ➢ AUC-ROC:     {roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "# Ejecution.\n",
    "\n",
    "# 1. Plot Learning Curves (Loss and Accuracy).\n",
    "print(\"Training curves\")\n",
    "plot_training_curves(history_fe, history_ft)\n",
    "\n",
    "# 2. Plot Final Evaluation (Confusion Matrix and ROC).\n",
    "print(\"Evaluation plots\")\n",
    "plot_confusion_matrix_and_roc(test_labels, test_preds, test_probs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
