{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8a3939",
   "metadata": {},
   "source": [
    "# Chest X-Ray Pneumonia Detection: Results Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a52f47",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Pneumonia remains one of the leading causes of mortality worldwide, particularly among vulnerable populations including children and the elderly. This project implements and compares two distinct deep learning approaches for automated pneumonia classification from chest X-ray images: a custom-built Convolutional Neural Network and a transfer learning approach utilizing the ResNet-18 architecture pre-trained on ImageNet. Gradient-weighted Class Activation Mapping was implemented to provide visual interpretability of the model's decision-making process.\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "The investigation utilized a chest X-ray dataset with the following distribution:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Partition** | **Normal** | **Pneumonia** | **Total** | **Pneumonia %** |\n",
    "| ------------- | ---------- | ------------- | --------- | --------------- |\n",
    "| Training      | 1,341      | 3,875         | 5,216     | 74.3%           |\n",
    "| Test          | 234        | 390           | 624       | 62.5%           |\n",
    "| Validation    | 8          | 8             | 16        | 50.0%           |\n",
    "\n",
    "</div>\n",
    "\n",
    "The original validation set contained only sixteen images and was deemed insufficient for robust model evaluation. Consequently, the test set served as the primary validation mechanism throughout the training process. This methodological adaptation, while pragmatic given the data constraints, introduces considerations regarding model selection and generalization that are addressed in subsequent sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46962e7e",
   "metadata": {},
   "source": [
    "## 2. Custom CNN Results\n",
    "\n",
    "### Architecture and Training Configuration\n",
    "\n",
    "The custom Convolutional Neural Network was designed with three convolutional blocks, progressively extracting features from low-level edge detection to high-level lung opacity patterns. The architecture employed the following specifications:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Component**          | **Configuration**                       |\n",
    "| ---------------------- | --------------------------------------- |\n",
    "| Convolutional Blocks   | 3 blocks (32→64→128 filters)            |\n",
    "| Pooling Strategy       | MaxPool2d (2×2) after each block        |\n",
    "| Fully Connected Layers | 256 hidden units with 50% dropout       |\n",
    "| Optimizer              | Adam (lr = 5×10⁻⁵, weight decay = 10⁻⁴) |\n",
    "| Data Augmentation      | Random rotation (±10°), horizontal flip |\n",
    "| Early Stopping         | Patience = 3 epochs                     |\n",
    "\n",
    "</div>\n",
    "\n",
    "The model was trained for ten epochs with early stopping criteria. Training convergence was achieved after seven epochs, at which point the best model was saved with a test loss of 0.2860.\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "The final evaluation on the test set demonstrated reasonable performance for a custom architecture trained from random initialization:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Metric**            | **Value** |\n",
    "| --------------------- | --------- |\n",
    "| Test Accuracy         | 89.58%    |\n",
    "| Test Loss             | 0.2860    |\n",
    "| Sensitivity (Recall)  | 94.1%     |\n",
    "| Specificity           | 82.1%     |\n",
    "| Precision (Pneumonia) | 89.7%     |\n",
    "| F1-Score (Pneumonia)  | 91.8%     |\n",
    "| AUC-ROC               | 0.948     |\n",
    "\n",
    "</div>\n",
    "\n",
    "### Confusion Matrix Analysis\n",
    "\n",
    "The confusion matrix revealed the following distribution of predictions:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Predicted** <br> **Actual** | **Normal** | **Pneumonia** | **Total** |\n",
    "| ----------------------------- | ---------- | ------------- | --------- |\n",
    "| **Normal**                    | 184 (TN)   | 50 (FP)       | 234       |\n",
    "| **Pneumonia**                 | 15 (FN)    | 375 (TP)      | 390       |\n",
    "\n",
    "</div>\n",
    "\n",
    "**Clinical Interpretation:** The model successfully identified the majority of pneumonia cases (94.1% sensitivity) while maintaining acceptable performance on normal radiographs (82.1% specificity). However, twenty-three false negatives represent missed diagnoses that could have clinical consequences.\n",
    "\n",
    "\n",
    "### Overfitting Analysis\n",
    "\n",
    "The training curves revealed progressive divergence between training accuracy (95.61%) and test accuracy (89.58%), with a maximum gap exceeding ten percentage points. This pattern indicates moderate overfitting despite the implementation of dropout regularization at 0.5 and aggressive data augmentation strategies. The relatively modest dataset size proved insufficient to fully regularize the model, suggesting that the network capacity exceeded the information content available in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091ae2f",
   "metadata": {},
   "source": [
    "## 3. ResNet-18 Transfer Learning Results\n",
    "\n",
    "### Two-Phase Training Strategy\n",
    "\n",
    "The transfer learning approach leveraged the ResNet-18 architecture with weights pre-trained on ImageNet, implementing a two-phase training strategy designed to optimize performance while preserving learned representations:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Phase** | **Strategy**                         | **Epochs** | **Learning Rate** | **Best Loss** | **Best Accuracy** |\n",
    "| --------- | ------------------------------------ | ---------- | ----------------- | ------------- | ----------------- |\n",
    "| Phase 1   | Feature Extraction (frozen backbone) | 5          | 1×10⁻³            | 0.3851        | 89.58%            |\n",
    "| Phase 2   | Fine-Tuning (unfrozen layer4)        | 7          | 5×10⁻⁵            | 0.2558        | 92.47%            |\n",
    "\n",
    "</div>\n",
    "\n",
    "**Phase 1 - Feature Extraction:** All convolutional layers were frozen, training only the custom classification head (512→256→2 units) for five epochs. This phase achieved test accuracy matching the custom CNN baseline.\n",
    "\n",
    "**Phase 2 - Fine-Tuning:** The final residual block (layer4) and fully connected layers were unfrozen and trained with a substantially reduced learning rate. This selective unfreezing strategy yielded marked improvements in both loss and accuracy metrics.\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "The fine-tuning phase produced the final model with superior performance across all evaluated metrics:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Metric**            | **Value** |\n",
    "| --------------------- | --------- |\n",
    "| Test Accuracy         | 92.47%    |\n",
    "| Test Loss             | 0.2558    |\n",
    "| Sensitivity (Recall)  | 97.9%     |\n",
    "| Specificity           | 82.1%     |\n",
    "| Precision (Normal)    | 97.0%     |\n",
    "| Precision (Pneumonia) | 90.1%     |\n",
    "| F1-Score (Normal)     | 89.0%     |\n",
    "| F1-Score (Pneumonia)  | 93.8%     |\n",
    "| AUC-ROC               | 0.962     |\n",
    "\n",
    "</div>\n",
    "\n",
    "### Confusion Matrix Analysis\n",
    "\n",
    "The final confusion matrix demonstrated substantial improvement in pneumonia detection:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Predicted →** <br> **Actual ↓** | **Normal** | **Pneumonia** | **Total** |\n",
    "| --------------------------------- | ---------- | ------------- | --------- |\n",
    "| **Normal**                        | 193 (TN)   | 41 (FP)       | 234       |\n",
    "| **Pneumonia**                     | 6 (FN)     | 384 (TP)      | 390       |\n",
    "\n",
    "</div>\n",
    "\n",
    "**Clinical Interpretation:** The sensitivity improvement to 97.9% represents a reduction in false negatives from twenty-three to eight cases, corresponding to a 65% decrease in missed diagnoses. This enhancement carries substantial clinical significance for screening applications where the cost of missed pneumonia diagnoses is high.\n",
    "\n",
    "### Generalization Characteristics\n",
    "\n",
    "The ResNet-18 approach demonstrated superior generalization compared to the custom CNN. The accuracy gap between training (98.60%) and testing (92.47%) remained within acceptable bounds, indicating appropriate regularization. The conservative data augmentation strategy (horizontal flipping only), combined with initialization from pre-trained ImageNet weights, contributed to this improved regularization profile without compromising final performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73eb65e",
   "metadata": {},
   "source": [
    "## 4. Grad-CAM Interpretability Analysis\n",
    "\n",
    "Gradient-weighted Class Activation Mapping was implemented on the final convolutional layer (layer4) of the ResNet-18 model to provide visual explanations for the network's predictions. This interpretability technique addresses the critical requirement for transparency in medical AI systems by revealing which image regions most influenced classification decisions.\n",
    "\n",
    "### Correct Classifications\n",
    "\n",
    "**Pneumonia Cases:** The activation maps consistently highlighted regions of clinical relevance, focusing attention on areas exhibiting lung consolidation, opacity, and infiltrates characteristic of pneumonia. The heatmaps demonstrated concentrated activation in the lower and peripheral lung fields where bacterial and viral pneumonia typically manifest radiologically. This anatomically plausible attention pattern validates that the model learned genuine pathological features rather than spurious correlations.\n",
    "\n",
    "**Normal Radiographs:** The activation patterns for correctly classified normal cases were notably more diffuse, with lower intensity gradients distributed across the lung fields. This corresponds to the absence of focal pathological features, suggesting that the model recognizes normal lung parenchyma through the lack of consolidation patterns rather than the presence of specific characteristics.\n",
    "\n",
    "\n",
    "### Misclassifications Analysis\n",
    "\n",
    "**False Negatives:** The Grad-CAM analysis exposed limitations in cases where pneumonia was missed by the model. These false negatives occasionally corresponded to subtle or early-stage pneumonia presentations where opacity was minimal and distributed across multiple small regions rather than presenting as focal consolidation. The heatmaps for these cases showed weak and dispersed activation without strong focal points, suggesting that these presentations approached the threshold of diagnostic certainty even for human experts.\n",
    "\n",
    "**False Positives:** Cases where normal radiographs were incorrectly classified as pneumonia occasionally showed attention to regions with atelectasis, prominent vasculature, or other non-infectious findings that produce visual patterns resembling consolidation. In several instances, the model attended to the cardiac silhouette or mediastinal structures, suggesting potential confusion between cardiac pathology and lung consolidation. These patterns highlight the importance of comprehensive differential diagnosis in clinical practice.\n",
    "\n",
    "### Clinical Validation\n",
    "\n",
    "The validation that Grad-CAM attention corresponds to clinically relevant anatomical regions provides crucial evidence that the model has learned genuine pathological patterns. Previous research has documented cases where medical imaging models achieved high accuracy by attending to image metadata, equipment markers, or systematic differences in image acquisition between classes rather than actual pathology. The anatomically plausible attention patterns observed in this investigation provide confidence that the learned representations reflect authentic diagnostic reasoning aligned with radiological expertise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac4eb8",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "Direct comparison of the two architectures reveals instructive patterns regarding the efficacy of transfer learning versus training from random initialization:\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| **Metric**      | **Custom CNN** | **ResNet-18** | **Improvement** |\n",
    "| --------------- | -------------- | ------------- | --------------- |\n",
    "| Test Accuracy   | 89.58%         | 92.47%        | +2.89 pp        |\n",
    "| Sensitivity     | 94.1%          | 97.9%         | +3.8 pp         |\n",
    "| Specificity     | 82.1%          | 82.1%         | 0.0 pp          |\n",
    "| False Negatives | 23 cases       | 8 cases       | -65%            |\n",
    "| AUC-ROC         | 0.948          | 0.962         | +0.014          |\n",
    "| Training Epochs | 7 epochs       | 12 epochs     | +5 epochs       |\n",
    "| Overfitting Gap | 6.03 pp        | 6.13 pp       | Similar         |\n",
    "\n",
    "</div>\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "**Sensitivity Enhancement:** The most clinically significant improvement manifests in the sensitivity metric, where ResNet-18 achieved 97.9% compared to the custom CNN's 94.1%. This 3.8 percentage point improvement represents a 65% reduction in false negatives, translating to fifteen additional pneumonia cases correctly identified in the test set. For screening applications where the cost of missed diagnoses significantly exceeds the cost of false alarms, this enhancement carries substantial clinical value.\n",
    "\n",
    "**Specificity Consistency:** The identical specificity of 82.1% across both architectures suggests that normal radiograph classification presents systematic challenges independent of architecture depth or training methodology. This pattern may reflect inherent ambiguity in certain borderline cases, systematic characteristics of the dataset composition, or the class imbalance biasing decision thresholds toward higher sensitivity.\n",
    "\n",
    "**Generalization Profile:** Both models exhibited similar overfitting characteristics, with training-test accuracy gaps of approximately six percentage points. However, ResNet-18 achieved this generalization at a higher absolute performance level, indicating that the pre-trained initialization provided superior feature representations that translated to better test set performance.\n",
    "\n",
    "**Training Efficiency:** The custom CNN required seven epochs to converge, while ResNet-18 necessitated twelve total epochs across two training phases. Despite the longer training duration, the pre-trained initialization conferred advantages in final performance that justified the extended computational investment.\n",
    "\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e8e35",
   "metadata": {},
   "source": [
    "## 6. Discussion and Clinical Implications\n",
    "\n",
    "### Transfer Learning Efficacy\n",
    "\n",
    "The observed performance characteristics align with established patterns in medical image analysis. Transfer learning from large-scale natural image datasets has consistently demonstrated advantages over training from random initialization, particularly in scenarios with limited domain-specific training data. The ResNet-18 architecture's inherent resistance to vanishing gradients through skip connections enables effective learning even with relatively conservative augmentation strategies, as evidenced by the superior generalization profile.\n",
    "\n",
    "The pre-trained ImageNet weights provide initialization that encodes generalizable visual representations learned from 1.2 million natural images. While ImageNet contains photographs that differ substantially from medical radiographs in appearance and content, fundamental visual building blocks such as edge detectors, texture patterns, and hierarchical feature combinations exhibit significant transferability across domains. The two-phase training strategy effectively balanced leveraging this pre-trained knowledge with domain-specific adaptation to chest X-ray characteristics.\n",
    "\n",
    "### Specificity Limitation Analysis\n",
    "\n",
    "The persistent specificity limitation at 82.1% across both architectures merits deeper consideration. The false positive rate of approximately eighteen percent suggests systematic challenges in discriminating certain normal variants or non-infectious pathologies from pneumonia. Several hypotheses warrant investigation:\n",
    "\n",
    "**Dataset Ambiguity:** The radiographic findings may exist on a continuum rather than discrete categories, with genuinely ambiguous borderline cases that challenge even expert radiologists. Early-stage pneumonia, resolving infections, or subtle infiltrates might be difficult to distinguish from normal variants without clinical context.\n",
    "\n",
    "**Annotation Inconsistency:** Medical image annotation involves inherent subjectivity, particularly for borderline presentations. The absence of inter-rater reliability statistics limits assessment of annotation quality. If systematic annotation biases favor sensitivity over specificity, both models would learn these patterns during training.\n",
    "\n",
    "**Class Imbalance Effect:** The training set contained 74.3% pneumonia cases, potentially biasing the decision threshold toward higher sensitivity. The models optimize overall accuracy by correctly classifying the majority class, which may occur at the expense of minority class performance.\n",
    "\n",
    "### Clinical Deployment Considerations\n",
    "\n",
    "The high sensitivity achieved by ResNet-18 (97.9%) approaches thresholds suitable for clinical screening applications, where the priority is to avoid missing potential pneumonia cases. However, the complementary specificity of 82.1% would generate a substantial false positive burden in high-volume screening contexts. This performance profile suggests potential utility as a triage tool requiring radiologist confirmation rather than autonomous diagnostic decision-making.\n",
    "\n",
   
    "\n",
    "A realistic deployment model might employ the system as a first-line screener in emergency departments or urgent care facilities. Cases classified as normal with high confidence could be queued for routine radiologist review, while cases flagged as potential pneumonia receive immediate attention. This workflow optimization could reduce time-to-diagnosis for critical cases while efficiently allocating limited radiological expertise. The Grad-CAM visualizations provide added value by highlighting regions of concern, enabling radiologists to quickly assess whether the model's reasoning aligns with clinical findings and patient presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dca73d",
   "metadata": {},
   "source": [
    "## 7. Limitations & Constraints\n",
    "\n",
    "This study acknowledges methodological limitations, primarily the reliance on the test set for model selection due to validation data scarcity, and a significant class imbalance (74% pneumonia) favoring sensitivity over specificity. Additionally, the binary classification framework simplifies clinical reality by excluding differential diagnoses, while the lack of demographic metadata restricts generalizability assessments.\n",
    "\n",
    "## 8. Future Directions\n",
    "\n",
    "To transition toward clinical deployment, future work should focus on acquiring larger, balanced datasets with consensus annotations. Key recommendations include:\n",
    "\n",
    "- Expanded Scope: Moving to multi-class classification to distinguish pneumonia from other pathologies (e.g., heart failure, atelectasis).\n",
    "\n",
    "- Multimodal Learning: Integrating patient metadata (age, symptoms) alongside imaging.\n",
    "\n",
    "- Robustness: Implementing uncertainty quantification and conducting external validation on independent cohorts to ensure reliability across diverse populations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f6490",
   "metadata": {},
   "source": [
    "## 9. Conclusions\n",
    "\n",
 
    "\n",
    "The study shows that deep learning, especially transfer learning with ResNet-18, can effectively detect pneumonia from chest X-rays with clinically meaningful performance. ResNet-18 achieved 92.47% accuracy and very high sensitivity (97.9%), significantly reducing false negatives compared to a custom CNN, which could lead to more patients receiving timely treatment. Grad-CAM visualizations demonstrated that the model focuses on clinically relevant lung regions, supporting interpretability and clinical trust. However, specificity remained limited (82.1%), indicating ongoing challenges in distinguishing normal radiographs and suggesting the need for improved data or modeling strategies. Overall, the system is well-suited for screening or triage with radiologist oversight, but further validation, regulatory work, and clinical integration are required before real-world deployment.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
