{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa685c65",
   "metadata": {},
   "source": [
    "# Pneumonia Classification in Chest X-rays using CNN\n",
    "This notebook presents the development of a Convolutional Neural Network (CNN) designed to detect pneumonia from **chest X-ray images**.\n",
    "\n",
    "### 1. Environment Setup and Imports\n",
    "In this section, the necessary libraries for tensor processing (PyTorch), visualization (Matplotlib), and evaluation metrics were loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced64494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys \n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1903",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Preprocessing\n",
    "The system paths were configured to access local modules and the dataloaders were initialized. An image size of 228x228 was selected to balance detail and computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689c7963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader variable defined: True\n"
     ]
    }
   ],
   "source": [
    "# Go up one level to reach the project root and enter 'src'\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Import custom dataloaders\n",
    "from src.data.dataloaders import get_loaders\n",
    "\n",
    "# Execute the function to get data loaders\n",
    "# batch_size=32 is a stable standard for training\n",
    "train_loader, test_loader = get_loaders(batch_size=32, img_size=228)\n",
    "\n",
    "print(f\"train_loader variable defined: {train_loader is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30a8f0",
   "metadata": {},
   "source": [
    "### 3. Model Architecture (PneumoniaCNN)\n",
    "A custom architecture with 3 convolutional blocks was designed. Each block extracted features ranging from low-level edges to high-level lung opacity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f67e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure was successfully verified.\n"
     ]
    }
   ],
   "source": [
    "class PneumoniaCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(PneumoniaCNN, self).__init__()\n",
    "        \n",
    "        # BLOCK 1: Initial feature extraction\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # BLOCK 2: Depth increase\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # BLOCK 3: Complex features extraction\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            # Output size: 28x28x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # Regularization was added to prevent overfitting\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# The model was instantiated and dimensions were verified\n",
    "model = PneumoniaCNN(num_classes=2)\n",
    "print(\"Model structure was successfully verified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3d3ce",
   "metadata": {},
   "source": [
    "### 4. Training Configuration\n",
    "The hardware was selected. Since an Apple M1 chip was used, the Metal Performance Shaders (MPS) backend was prioritized to leverage the integrated GPU, falling back to CPU only if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "784351ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: Apple Silicon GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Hardware selection (Optimized for Apple M1/M2/M3)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Training on: Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Training on: NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Training on: CPU\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# CrossEntropyLoss was chosen for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam optimizer was initialized with a learning rate of 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# A scheduler was implemented to reduce LR on plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7d35b",
   "metadata": {},
   "source": [
    "### 5. Training Loop Definition\n",
    "A function was created to manage the training process, error calculation, and weight optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36571732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=10):\n",
    "    history = {'train_loss': [], 'test_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct_train / total_train\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        test_loss, correct_test, total_test = 0.0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_loss = test_loss / len(test_loader)\n",
    "        test_acc = 100 * correct_test / total_test\n",
    "\n",
    "        # Save the best model based on test loss\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Best model saved\")\n",
    "        \n",
    "        # Metrics were stored in history\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.2f}%\")\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca10f1",
   "metadata": {},
   "source": [
    "### 6. Visualization of Results\n",
    "A plotting function was defined to evaluate the model's convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2304af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['test_loss'], label='Test')\n",
    "    plt.title('Loss History')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['test_acc'], label='Test')\n",
    "    plt.title('Accuracy History')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872e863",
   "metadata": {},
   "source": [
    "### 7. Experiment Execution\n",
    "The training process was executed for 10 epochs and the results were visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a51ee36",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Plot the training results\u001b[39;00m\n\u001b[1;32m     15\u001b[0m plot_results(history)\n",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m running_loss, correct_train, total_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 11\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define number of epochs\n",
    "NUM_EPOCHS = 10 \n",
    "\n",
    "# Train the model\n",
    "history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    epochs=NUM_EPOCHS\n",
    ")\n",
    "\n",
    "# Plot the training results\n",
    "plot_results(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
